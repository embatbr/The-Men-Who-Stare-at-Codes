For now we learnt <a href="http://themenwhostareatcodes.wordpress.com/2014/03/02/neural-networks-in-a-nutshell/" title="McCulloch-Pitts" target="_blank">what an ANN is and it's basic element</a> and the <a href="http://themenwhostareatcodes.wordpress.com/2014/03/07/neural-networks-in-a-nutshell-2/" title="Perceptron" target="_blank">simplest neural net ever</a>. Before start this post properly, let's understand some concepts first.

<!--more-->

The Perceptron converged in our example because the problem was *lineraly separable*, what means we could divide it in two classes using a *hyperplane* (in that case, a *straight line*). That's why I defined the stopping rule as "**stop when there's no errors, *bitch***", because someday it happens. If just one example of class `C1` where in the region of class `C2`, we couldn't draw a line dividing both classes. So, if you don't know if the problem is *linearly separable* (what could lead to an endless loop), change the *stopping rule* to abort training after a predefined number of epochs:

[code language="python"]
    def training(self, examples, max_epochs=None):
        epochs = 0

        while True:
            epochs = epochs + 1
            error_count = 0

            for (input_vector, desired_output) in examples:
                actual_output = self.neuron.fire(input_vector)
                error = desired_output - actual_output

                if error != 0:
                    learned = self.lrn_rate*error
                    self.neuron.update(input_vector, learned)
                    error_count = error_count + 1

            if error_count == 0:
                return epochs
            elif max_epochs and (epochs > max_epochs):
                return False
[/code]

But sometimes what doesn't seem to be separable by one line can be by two or more. This way we still can divide the classes in two regions. To understand how to "cheat" this Perceptron's weakness, let's first learn about Multiclass Perceptron.

## 3 - Multiclass Perceptron

Taking our equation from previous post (as shown in *Eq. 7*) let's add another line (*Eq. 8*) crossing the first

- (7) $latex x_2 = -5x_1 + 2$
- (8) $latex x_2 = 3x_1 + 4$

so the plane $latex x_1x_2$ is divided in four different regions:

- C1: above *Eq. 7* and *Eq. 8*
- C2: above *Eq. 7* and below *Eq. 8*
- C3: below *Eq. 7* and above *Eq. 8*
- C4: below *Eq. 7* and *Eq. 8*

Having four regions we need two neurons, one for each line. With two neurons we have two outputs (and four *linearly separable* classes), defined as:

- C1: (output_1, output_2) = (1, 1)
- C2: (output_1, output_2) = (1, -1)
- C3: (output_1, output_2) = (-1, 1)
- C4: (output_1, output_2) = (-1, -1)

Then we need to build a *layer* of perceptrons. Basically what is done is a class containing a list of perceptrons (remember each one is **independent** from the others):

[code language="python"]
class Layer(object):
    """A layer containing two or more perceptrons.
    """
    def __init__(self, input_size, num_perceptrons=2, lrn_rates=[1, 1],
                 activations=[signal, signal]):
        """Not checking if lrn_rates and activations have the length equals to
        num_perceptrons.
        """
        self.perceptrons = [Perceptron(input_size, lrn_rates[i], activations[i])
                            for i in range(num_perceptrons)]

    def fire(self, inputs):
        return [perceptron.fire(inputs) for perceptron in self.perceptrons]

    def training(self, inputs_vector, outputs_vector, max_epochs):
        """outputs_vector is a list containing the same number of elements of
        perceptron. Each element is another list with length equals to inputs_vector's
        length.
        """
        epochs = 0

        for (perceptron, outputs) in zip(self.perceptrons, outputs_vector):
            epochs_per_perceptron = perceptron.training(inputs_vector, outputs,
                                                        max_epochs)
            if not epochs_per_perceptron:
                return epochs_per_perceptron

            epochs = epochs + epochs_per_perceptron

        return epochs
[/code]

It's importante to notice that each *perceptron* receives all inputs, no matter if it's one, two or ten in the layer. Also, as the classes are *linearly separable*, we can train one *perceptron* per time. So, now, our Multiclass Perceptron is composed of two layers: an input layer and an output layer (where the neurons are).

The code to test this new Perceptron of ours (with two neurons) is basically the same:

[code language="python"]
def classify(y, x, a, b):
    if y >= a*x + b:
        return 1 # class C1
    return -1 # class C2

def gen_examples(num_examples, a, b, c, d):
    inputs_vector = []
    outputs_vector = [[], []]

    for _ in range(num_examples):
        x1 = uniform(-10, 10)
        x2 = uniform(-10, 10)

        inputs_vector.append([x1, x2])
        outputs_vector[0].append(classify(x1, x2, a, b))
        outputs_vector[1].append(classify(x1, x2, c, d))

    return (inputs_vector, outputs_vector)

def layer(lrn_rates, num_training, num_test, a, b, c, d):
    layer = Layer(2, lrn_rates=lrn_rates)

    (inputs_vector, outputs_vector) = gen_examples(num_training, a, b, c, d)
    print('#TRAINING (max_epochs = 80)')
    epochs = layer.training(inputs_vector, outputs_vector, 80)
    print(('epochs: %d' % epochs) if epochs else 'training aborted')

    (inputs_vector, outputs_vector) = gen_examples(num_test, a, b, c, d)
    print('#TESTING')
    error_count = load_test(layer, inputs_vector, outputs_vector)
    print('error_count:', error_count)
[/code]

Now, imagine we keep the lines from *Eq. 7* and *Eq. 8*, but again we just have two classes:

- C1: above *Eq. 7* and *Eq. 8*
- C2: otherwise

This means `C2`, `C3` and `C4` are all called just `C2`. There's no way to draw a line separating the new classes `C1` and `C2`, but we could filter the previously shown *layer*'s outputs (two numbers `y1` and `y2`) into just one, using a "*neuron*". This new *neuron*'s filter rule would be something like:

- C1: (`y1`, `y2`) = (1, 1)
- C2: otherwise

Using the output *neuron* with a fixed *bias* in the interval (`1.5`, `-2`] we could define who is `C1` and who is `C2`. But this *filter* would just be used after training the ANN, as it's weights must always be `1`, and through it's output is impossible to reach `y1` and `y2`. The *activation function* is not **bijective**.

This network described above is a draft of an ANN known as **Multilayer Perceptron**. But before that, as I always do (*bastard*), let me show you the **Adaline** network.

## 4 - Adaline

Adaline comes from **ADAptive LINear Element** (previously **ADAptive LInear NEuron**), an ANN based on the *McCulloch-Pitts perceptron*, but without the *activation function* (or, more precisely, a *linear activation function*). It was developed by **Bernard Widrow** and **Ted Hoff** at **Stanford University** in 1960. Similar to the Perceptron, the Adaline can classify multiple classes, when it's called Madaline (from Multiclass Adaline), a layer of independent Adalines. It's output is given by:

- (9) $latex y = \sum_{j=1}^{n} w_jx_j + b$

As we know, the *perceptron*'s learning rule is given by

- (10) $latex w_j(n + 1) = w_j(n) + \eta(d - y)x_j$
- (11) $latex b(n + 1) = b(n) + \eta(d - y)$

where $latex \eta$ is the *learning rate*, $latex d$ is the desired output and $latex y$ is the actual output. This can be composed into $latex \Delta w_j = \eta(d - y)x_j$ and *Eq. 10* and *Eq. 11* can be rewritten as:

- (12) $latex w_j(n + 1) = w_j(n) + \Delta w_j$
- (13) $latex b(n + 1) = b(n) + \Delta w_0$ (remember $latex w_0 = b$ and $latex x_0 = +1$)

The perceptron's *learning rule*, when using the *threshold function*, is called *Hebb's rule*. In our case we used the *signal function*, but the essence is the same. The rule used in our *adaline* is the *delta rule*, which uses *gradient descent* to adjust the weights. For an online training, the cost is $latex \varepsilon (w) = \frac{1}{2}(d - y)^2$ and $latex \Delta w_j(n) = \eta(-\frac{\partial \varepsilon}{\partial w_j})$, resulting in *Eq. 10* and *Eq. 11*. So, in practice *perceptron* and *adaline* have the same training rule (the *delta rule*), but the weights in the first are adjusted discretly, while in the second, continuously.

As *activation function* to this adaline, I used a linear function limited between `-1` and `1`:

[code language="python"]
def limited_linear(x):
    if x > 1:
        return 1
    elif x < -1:
        return -1
    return x
[/code]

Also,  I used *cross-validation*. I'm doing *online training* with no specific number of epochs. For each epoch, the weights are changed and later the validation set is fed to the net and the MSE is calculated using the formula $latex E = \frac{1}{M}\sum_{i=1}^{M}(d_i - y_i)^2$, where `M` is the number of inputs and $latex (d_i - y_i)^2$ is the squared error for the *i*-th input vector:

[code language="python"]
class Adaline(object):
    """Online learning Adaline.
    """
    def __init__(self, input_size, lrn_rate=1):
        """'input_size' is the length of the input.
        'lrn_rate' is the learning rate.
        """
        self.weights = [0]*input_size
        self.bias = 0
        self.lrn_rate = lrn_rate

    def fire(self, input_vector):
        summed = sum([i*w for (i,w) in zip(input_vector, self.weights)])
        return limited_linear(summed + self.bias)

    def training(self, training_examples, validation_examples):
        """Cross-validation training.
        """
        training_size = len(training_examples)
        validation_size = len(validation_examples)
        old_mse_valid = None

        while True:
            # training
            mse_train = 0
            for (input_vector, desired) in training_examples:
                output = self.fire(input_vector)
                error = desired - output
                mse_train = mse_train + (error*error)/2

                if error != 0:
                    delta = self.lrn_rate*error
                    self.weights = [(weight + delta*x) for (weight, x) in
                                    zip(self.weights, input_vector)]
                    self.bias = self.bias + delta
            mse_train = mse_train/training_size

            # validation
            mse_valid = 0
            for (input_vector, desired) in validation_examples:
                output = self.fire(input_vector)
                error = desired - output
                mse_valid = mse_valid + (error*error)/2
            mse_valid = mse_valid/validation_size

            if not old_mse_valid:
                old_mse_valid = mse_valid
            elif mse_valid < old_mse_valid:
                old_mse_valid = mse_valid
            elif mse_valid > old_mse_valid:
                return (mse_train, mse_valid)
[/code]

The use of an *activation function* not completely linear is because with the other (a totally linear function) the numbers overflowed (with value `inf`). Also, some sources shows this kind of *activation function*.

Some sources says the *Adaline* converges in the same way as the *Perceptron* (no error if the training set is *linearly separable*), others that it converges to the lowest MSE (makes sense too, LMS == Least Mean Square). I used the second option because it would take a really long time to achieve `MSE = 0`. When the actual MSE is higher than the previous one, I pull the plug.

The rest of the code is similar to the previous ones. You can find it <a href="https://github.com/embatbr/The-Men-Who-Stare-at-Codes/tree/master/posts/neural-networks-in-a-nutshell-3/code" target="_blank">here</a>.

## 5 - Multilayer Perceptron

Until now, our ANNs had only two layers, one with input nodes (that are not neurons) and other with output nodes. The *Perceptron* and *Adaline* neural networks contains one, and one only, layer of neurons. This makes they limited. Most problems in the real world, as the one exemplified in the *Overview* section, are nonlinear and with more than two classes. The problem showed in the beginning of this post, where we have two straight lines dividing the region in only two classes could be solved in these two ways

1. Output `(1, 1)` determines class `C1`; outputs `(1, -1)`, `(-1, 1)` and `(-1, -1)` determines class `C2`.
2. Insert an extra layer to filter the doubled output into just one.

but others cannot. Will we divide the space in thousands of regions and use a table to determine who is `C1` and who is `C2`? If so, let's forget ANNs and start searching another technique.

So, a *Multilayer Perceptron* (abbreviated as **MLP**) contains three basic features:

- Each neuron is activated by a *differentiable* nonlinear function.
- The network contains one or more layers between the input and output layers. These are known as *hidden layers*, because we can't say what they outputs are.
- All neurons from a layer are connected to all neurons of the next layer (*fully connected* graph) through weights.

[caption id="attachment_595" align="aligncenter" width="450"]<a href="http://themenwhostareatcodes.files.wordpress.com/2014/03/figure-08.png"><img class=" wp-image-595    " alt="figure-08" src="http://themenwhostareatcodes.files.wordpress.com/2014/03/figure-08.png?w=300" width="450" height="219" /></a> <strong>Figure 8</strong> Multilayer Perceptron with two hidden layers. Watch out for the high connected graph.[/caption]

The code below shows the implementation of one layer (similar to the class `Layer` in the module `perceptron`)

[code language="python"]
class NeuralLayer(object):
    """A layer of independent neurons.
    """
    def __init__(self, num_neurons, input_size, activation):
        self.neurons = [Neuron([0]*input_size, 0, activation)]*num_neurons

    def fire(self, input_vector):
        """Not checking if input_vector fits in the neurons' inputs.
        """
        return [neuron.fire(input_vector) for neuron in self.neurons]

    def __str__(self):
        ret = ''

        num_neurons = len(self.neurons)
        for (neuron, i) in zip(self.neurons, range(num_neurons)):
            ret = '%sneuron #%d\n%s\n' % (ret, i, neuron.__str__())

        return ret
[/code]

and the next shows our Multilayer Perceptron (the training algorithm is not implemented yet. It will be detailed in it's own section):

[code language="python"]
class MultilayerPerceptron(object):
    """A feedfoward neural network composed of N neural layers (1 output layer
    and N - 1 hidden layers).
    """
    def __init__(self, num_neurons_per_layer, input_size, activation, lrn_rate):
        """num_neurons_per_layer is a list of int.
        """
        num_inputs_per_layer = [input_size] + num_neurons_per_layer[: -1]
        num_layers = len(num_neurons_per_layer)

        self.layers = []
        for i in range(num_layers):
            layer = NeuralLayer(num_neurons_per_layer[i],
                                num_inputs_per_layer[i], activation)
            self.layers.append(layer)

        self.lrn_rate = lrn_rate

    def fire(self, input_vector):
        output = input_vector
        for layer in self.layers:
            output = layer.fire(output)
        return output
[/code]

Notice the structure of both classes are similar. A `NeuralLayer` is a list of neurons which length is the length of the layer's output. The same though applicable to the class `MultilayerPerceptron`.

Before moving to the *backpropagation algorithm* let's first take a look in **batch learning** and **online learning**.

### Batch Learning and Online Learning

Considering a *training sample* $latex T = \{\textbf{x}(n), \textbf{d}(n)\}_{n=1}^{N}$ used to train a MLP in a supervised manner. The *error signal* produced at output *j* is

- (14) $latex e_j(n) = d_j(n) - y_j(n)$

where $latex d_j(n)$ is the *j*-th element of the desired-response vector $latex \textbf{d}(n)$. The *instantaneous error energy* of neuron *j* is

- (15) $latex \varepsilon_j(n) = \frac{1}{2}e_j^2(n)$

Summing the error-energy contributions of all neurons in the output layer, we express the *total instantaneous error energy* of the whole network as

- (16) $latex \varepsilon(n) = \sum_{j=1}^{C} \varepsilon_j(n) = \frac{1}{2}\sum_{j=1}^{C} e_j^2(n)$

where *C* is the number of neurons in the output layer. With the training sample consisting of *N* examples, the *error energy averaged over the training sample*, or the *empirical risk*, is defined by

- (17) $latex \varepsilon_{av}(N) = \frac{1}{N}\sum_{n=1}^{N} \varepsilon(n) = \frac{1}{2N}\sum_{n=1}^{N}\sum_{j=1}^{C} e_j^2(n)$

Naturally, the "error energies" are functions dependent of the synaptic weights (i.e. free parameters) of the MLP.

In batch method the adjustments of weights occur *after* the presentation of *all* the *N* examples in the training sample *T* (an *epoch*). The cost function is the $latex \varepsilon_{av}$ (*Eq. 17*) and for each epoch of training the examples in the training set *T* are *randomly shuffled*. Batch learning has the disadvantage of demand high *storage requirements*.

In online method the adjustments of weights occur *when an example is presented*. The cost function is the $latex \varepsilon(n)$. As the above, after each epoch the training sample is randomly shuffled. The online method works better than the batch method when there's *redundancy* in the training sample and is easier to implement.

The online method will be the one adopted for our backpropagation implementation, but this is a subject for a whole new post.

## References

- <a href="http://www.amazon.com/Neural-Networks-Learning-Machines-Edition/dp/0131471392" target="_blank">Neural Networks and Learning Machines – 3rd Ed – Haykin, Simon – Pearson</a>.
- <a href="http://prolland.free.fr/works/ai/docs/neuro-intro.pdf" target="_blank">An introduction to Neural Networks – 8th Ed. – Kröse, Ben; van der Smagt, Patrick – University of Amsterdam</a>.
- <a href="http://www.amazon.com/Machine-Learning-Tom-M-Mitchell/dp/0070428077" target="_blank">Machine Learning - Tom Mitchell - McGraw-Hill</a>.
- <a href="http://en.wikipedia.org/wiki/Delta_rule" target="_blank">Delta rule - Wikipedia</a>.
- <a href="http://en.wikipedia.org/wiki/Mean_squared_error" target="_blank">Mean Squared Error - Wikipedia</a>.
